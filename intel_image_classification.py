# -*- coding: utf-8 -*-
"""intel-image-classification.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1C5FRJS2WLYrWStZhmLNoiug8ggDxloFn

# *Samuel Andrey Aji Prasetya*

*Dataset: https://www.kaggle.com/datasets/puneet6060/intel-image-classification* <br>
*This notebook run on kaggle*
---

## Konfigurasi API kaggle
*Digunakan saat di google colab. Saat ini notebook di jalankan menggunakan kaggle*
"""

# ! chmod 600 /content/kaggle.json
# ! KAGGLE_CONFIG_DIR=/content/ kaggle datasets download -d sujaykapadnis/emotion-recognition-dataset
# import zipfile
# zip_file = zipfile.ZipFile('/content/emotion-recognition-dataset.zip', 'r')
# zip_file.extractall('/content/')

"""## Import Package
*Import Semua package/library yang dibutuhkan*
"""

import tensorflow as tf
from PIL import Image
import pandas as pd
import numpy as np
import os

from tensorflow.keras.optimizers.experimental import Adamax
from tensorflow.keras.applications import EfficientNetB0
from tensorflow.keras.models import Model
import time

from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.applications.densenet import preprocess_input as densePI

import matplotlib.pyplot as plt

"""## Mendefinisikan direktori dataset"""

# Base directory dataset pada kaggle
BASE_DIR = '/kaggle/input/intel-image-classification/seg_train/seg_train'

"""## Fungsi untuk membaca file gambar pada direktori"""

# Fungsi untuk membaca file gambar dalam sebuah direktori dan subdirektorinya
def read_files(startpath):
    image_files = []  # Daftar untuk menyimpan path file gambar
    for dirname, dirnames, filenames in os.walk(startpath):
        for filename in filenames:
            # Menambahkan path lengkap dari setiap file gambar ke dalam daftar
            image_files.append(os.path.join(dirname, filename))
    return image_files  # Mengembalikan daftar path file gambar

"""## Membaca resolusi unik pada dataset"""

# Mengambil daftar lengkap path file gambar
full_dirs = read_files(BASE_DIR)

# Daftar untuk menyimpan ukuran gambar dan jumlah file gambar
image_sizes = []  # ukuran gambar
num_image_files = 0  # jumlah file gambar

# Mengiterasi setiap file gambar
for file in full_dirs:
    # Membuka gambar menggunakan PIL
    try:
        image = Image.open(file)
        width, height = image.size
        image_sizes.append(f'{width}x{height}')  # Menyimpan ukuran gambar
        num_image_files += 1  # Menambah jumlah file gambar
    except Exception as e:
        print(f"Error processing {file}: {e}")

# Mendapatkan ukuran gambar unik
unique_sizes = set(image_sizes)

# Mencetak hasil
print(f'Total jumlah file gambar: {num_image_files}')
print(f'Total jumlah ukuran gambar unik: {len(unique_sizes)}')
print(f'10 ukuran gambar unik pertama: \n{list(unique_sizes)[:10]}')

"""## Mendapatkan informasi pada setiap label dataset"""

# Mengambil daftar label dari direktori utama dataset
category = os.listdir(BASE_DIR)

# Jumlah label atau class pada dataset
NUM_CLASS = len(category)

print(f"Dataset ini mempunyai: {NUM_CLASS} label\n")

total_data = 0

# Iterasi melalui setiap label
for label in category:
    # Membuat path lengkap ke direktori label
    label_dir = os.path.join(BASE_DIR, label)

    # Menghitung jumlah gambar untuk label tersebut
    num_images = len(os.listdir(label_dir))
    total_data += num_images

    print(f"Label {label}: {num_images}")

print(f"\nTotal Data: {total_data}")

"""## Augmentasi gambar"""

size = (150 ,150)
batch = 32
val_split = 0.2

dataGenerator = ImageDataGenerator(
    rotation_range=20,
    horizontal_flip=True,
    shear_range=0.3,
    zoom_range=0.3,
    fill_mode = 'nearest',
    preprocessing_function = densePI,
    validation_split = val_split
)

train_data = dataGenerator.flow_from_directory(
    directory = BASE_DIR,
    target_size= size,
    class_mode='categorical',
    batch_size = batch,
    shuffle = True,
    subset="training",
    seed = 0
)

validation_data = dataGenerator.flow_from_directory(
    directory = BASE_DIR,
    target_size= size,
    class_mode='categorical',
    batch_size = batch,
    shuffle = False,
    subset="validation",
    seed = 0
)

"""## Mengecek bentuk data latihan dan validasi"""

x,y = train_data.next()
i,j = validation_data.next()

print(f"Train shape : {x.shape},{y.shape} \n")
print(f"Valid shape : {i.shape},{j.shape} \n")

"""## Membuat model sequential"""

input_shape = (150, 150, 3)

# Menggunakan EfficientNetB0 sebagai model dasar, dengan menggunakan bobot pre-trained dari dataset ImageNet
base_model = EfficientNetB0(weights='imagenet', include_top=False, input_shape=input_shape)

# Melakukan iterasi pada semua layer dalam model dasar untuk membuatnya dapat dilatih (trainable)
for layer in base_model.layers:
    layer.trainable = True

# Membangun model menggunakan Sequential API dari Keras
model = tf.keras.models.Sequential([
    base_model,  # Menambahkan model dasar EfficientNetB0 ke dalam model
    tf.keras.layers.Conv2D(32, (3,3), activation='relu'),  # Menambahkan layer Conv2D dengan 32 filter
    tf.keras.layers.MaxPooling2D(2, 2),  # Menambahkan layer MaxPooling2D
    tf.keras.layers.GlobalAveragePooling2D(),  # Menambahkan layer GlobalAveragePooling2D
    tf.keras.layers.Flatten(),  # Melakukan flatten untuk mengubah hasil pooling menjadi vektor
    tf.keras.layers.Dense(512, activation='relu'),  # Menambahkan layer Dense dengan 512 unit
    tf.keras.layers.Flatten(),
    tf.keras.layers.Dense(1024, activation='relu'),  # Menambahkan layer Dense dengan 1024 unit
    tf.keras.layers.Dropout(0.5),  # Menambahkan layer Dropout untuk mengurangi overfitting
    tf.keras.layers.Dense(NUM_CLASS, activation='softmax')  # Menambahkan layer Dense output dengan aktivasi softmax
])

# Mengompilasi model dengan pengoptimal Adamax, fungsi loss categorical_crossentropy, dan metrik akurasi
model.compile(optimizer=Adamax(learning_rate=0.0001),
              loss='categorical_crossentropy', metrics=['accuracy'])

model.summary()

"""## Callback
*Callback untuk menghentikan proses epoch saat akurasi pada training set dan validation set mencapai >92%*
"""

class AccuracyStopCallback(tf.keras.callbacks.Callback):
    def on_epoch_end(self, epoch, logs=None):
        target_accuracy = 0.92

        current_accuracy = logs.get('accuracy')
        current_val_accuracy = logs.get('val_accuracy')

        if current_accuracy is not None and current_val_accuracy is not None:
            if current_accuracy >= target_accuracy and current_val_accuracy >= target_accuracy:
                print('\nAkurasi sudah mencapai >92% pada training set dan validation set')
                self.model.stop_training = True
stop_callback = AccuracyStopCallback()

"""## Melatih model"""

# Hitung waktu training
start_time = time.time()

# Training
history = model.fit(
    train_data,
    epochs=25,
    validation_data=(validation_data),
    callbacks=stop_callback,
    batch_size=32,
)

# Hitung waktu training
end_time = time.time()
result_time = end_time - start_time

# Menampilkan lama proses training
print(f"Training Time : {result_time}")
print(round(result_time/60) , ' Menit')
print(round(result_time % 60), ' Detik')

"""## Plot terhadap akurasi dan loss model"""

# Plot akurasi dan loss model
plt.plot(history.history['accuracy'], label='Training Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend()
plt.show()

plt.plot(history.history['loss'], label='Training Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()
plt.show()

"""## Menyimpan model dalam bentuk TF-Lite"""

# Menyimpan model ke dalam format H5
model.save('/kaggle/working/model/model.h5')

# Konversi model ke format TF-Lite
converter = tf.lite.TFLiteConverter.from_keras_model(model)
tflite_model = converter.convert()

# Menyimpan model TF-Lite
with open('/kaggle/working/model/model.tflite', 'wb') as f:
    f.write(tflite_model)